{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wbepu01LHJoL"
   },
   "source": [
    "# Trabajo Preparacion, visualizacion de Datos y Machine learning con Python<a class=\"tocSkip\">\n",
    "## Ciencia de datos en Produccion <a class=\"tocSkip\">\n",
    "\n",
    "**Estudiante:** Sebastián Cardona y Jose Miguel Millán\n",
    "\n",
    "**ID:** 1094910122 y 1088334182\n",
    "\n",
    "**Email:** sacardonar@uqvirtual.edu.co y josem.millanl@uqvirtual.edu.co\n",
    "\n",
    " \n",
    "**Ponga su nombre en el archivo de Jupyter Notebook \n",
    "Docente: [Jose R. Zapata](https://joserzapata.github.io)\n",
    "- https://joserzapata.github.io\n",
    "- https://twitter.com/joserzapata\n",
    "- https://www.linkedin.com/in/jose-ricardo-zapata-gonzalez/       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s_RCEnM3HJoL",
    "toc": true
   },
   "source": [
    "<h1>Contenido<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Definir-el-Problema-a-Resolver\" data-toc-modified-id=\"Definir-el-Problema-a-Resolver-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Definir el Problema a Resolver</a></span><ul class=\"toc-item\"><li><span><a href=\"#Describir-los-datos-de-entrada-y-salida\" data-toc-modified-id=\"Describir-los-datos-de-entrada-y-salida-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Describir los datos de entrada y salida</a></span></li></ul></li><li><span><a href=\"#Importar-Librerias\" data-toc-modified-id=\"Importar-Librerias-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Importar Librerias</a></span></li><li><span><a href=\"#Cargar-Datasets\" data-toc-modified-id=\"Cargar-Datasets-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Cargar Datasets</a></span></li><li><span><a href=\"#Descripcion--y-Limpieza-de-los-datos\" data-toc-modified-id=\"Descripcion--y-Limpieza-de-los-datos-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Descripcion  y Limpieza de los datos</a></span><ul class=\"toc-item\"><li><span><a href=\"#Identificacion-de-Variables\" data-toc-modified-id=\"Identificacion-de-Variables-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Identificacion de Variables</a></span></li><li><span><a href=\"#Analisis-General-Univariable-y-Bivariable\" data-toc-modified-id=\"Analisis-General-Univariable-y-Bivariable-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Analisis General Univariable y Bivariable</a></span></li><li><span><a href=\"#Eliminar-columnas-de-datos-Innecesarios\" data-toc-modified-id=\"Eliminar-columnas-de-datos-Innecesarios-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Eliminar columnas de datos Innecesarios</a></span></li><li><span><a href=\"#Remover-Datos-Duplicados-Exactos\" data-toc-modified-id=\"Remover-Datos-Duplicados-Exactos-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Remover Datos Duplicados Exactos</a></span></li><li><span><a href=\"#Procesamiento-de-Datos-Faltantes\" data-toc-modified-id=\"Procesamiento-de-Datos-Faltantes-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Procesamiento de Datos Faltantes</a></span><ul class=\"toc-item\"><li><span><a href=\"#Borrar-Filas\" data-toc-modified-id=\"Borrar-Filas-4.5.1\"><span class=\"toc-item-num\">4.5.1&nbsp;&nbsp;</span>Borrar Filas</a></span></li><li><span><a href=\"#Reemplazar-datos-faltantes-con-la-Media/-Moda/-Mediana-(Mean/-Mode/-Median-Imputation)\" data-toc-modified-id=\"Reemplazar-datos-faltantes-con-la-Media/-Moda/-Mediana-(Mean/-Mode/-Median-Imputation)-4.5.2\"><span class=\"toc-item-num\">4.5.2&nbsp;&nbsp;</span>Reemplazar datos faltantes con la Media/ Moda/ Mediana (Mean/ Mode/ Median Imputation)</a></span></li></ul></li><li><span><a href=\"#Remover-Datos-Duplicados-Exactos\" data-toc-modified-id=\"Remover-Datos-Duplicados-Exactos-4.6\"><span class=\"toc-item-num\">4.6&nbsp;&nbsp;</span>Remover Datos Duplicados Exactos</a></span></li><li><span><a href=\"#Analisis-Univariable\" data-toc-modified-id=\"Analisis-Univariable-4.7\"><span class=\"toc-item-num\">4.7&nbsp;&nbsp;</span>Analisis Univariable</a></span><ul class=\"toc-item\"><li><span><a href=\"#Variables-Numericas\" data-toc-modified-id=\"Variables-Numericas-4.7.1\"><span class=\"toc-item-num\">4.7.1&nbsp;&nbsp;</span>Variables Numericas</a></span></li><li><span><a href=\"#Variables-Categoricas\" data-toc-modified-id=\"Variables-Categoricas-4.7.2\"><span class=\"toc-item-num\">4.7.2&nbsp;&nbsp;</span>Variables Categoricas</a></span></li></ul></li><li><span><a href=\"#Analisis-Bivariable\" data-toc-modified-id=\"Analisis-Bivariable-4.8\"><span class=\"toc-item-num\">4.8&nbsp;&nbsp;</span>Analisis Bivariable</a></span><ul class=\"toc-item\"><li><span><a href=\"#Numericas-vs-Numericas\" data-toc-modified-id=\"Numericas-vs-Numericas-4.8.1\"><span class=\"toc-item-num\">4.8.1&nbsp;&nbsp;</span>Numericas vs Numericas</a></span></li><li><span><a href=\"#Categoricas-vs-Categoricas\" data-toc-modified-id=\"Categoricas-vs-Categoricas-4.8.2\"><span class=\"toc-item-num\">4.8.2&nbsp;&nbsp;</span>Categoricas vs Categoricas</a></span></li><li><span><a href=\"#Categoricas-vs-Numericas\" data-toc-modified-id=\"Categoricas-vs-Numericas-4.8.3\"><span class=\"toc-item-num\">4.8.3&nbsp;&nbsp;</span>Categoricas vs Numericas</a></span></li></ul></li><li><span><a href=\"#Procesamiento-de-Outliers\" data-toc-modified-id=\"Procesamiento-de-Outliers-4.9\"><span class=\"toc-item-num\">4.9&nbsp;&nbsp;</span>Procesamiento de Outliers</a></span><ul class=\"toc-item\"><li><span><a href=\"#Deteccion-de-Outliers-(Univariables-y-Bi-variables)\" data-toc-modified-id=\"Deteccion-de-Outliers-(Univariables-y-Bi-variables)-4.9.1\"><span class=\"toc-item-num\">4.9.1&nbsp;&nbsp;</span>Deteccion de Outliers (Univariables y Bi variables)</a></span></li><li><span><a href=\"#Remover-Outliers\" data-toc-modified-id=\"Remover-Outliers-4.9.2\"><span class=\"toc-item-num\">4.9.2&nbsp;&nbsp;</span>Remover Outliers</a></span></li></ul></li><li><span><a href=\"#Procesamiento-de-Outliers\" data-toc-modified-id=\"Procesamiento-de-Outliers-4.10\"><span class=\"toc-item-num\">4.10&nbsp;&nbsp;</span>Procesamiento de Outliers</a></span><ul class=\"toc-item\"><li><span><a href=\"#Deteccion-de-Outliers-(Univariables-y-Bi-variables)\" data-toc-modified-id=\"Deteccion-de-Outliers-(Univariables-y-Bi-variables)-4.10.1\"><span class=\"toc-item-num\">4.10.1&nbsp;&nbsp;</span>Deteccion de Outliers (Univariables y Bi variables)</a></span></li><li><span><a href=\"#Remover-Outliers\" data-toc-modified-id=\"Remover-Outliers-4.10.2\"><span class=\"toc-item-num\">4.10.2&nbsp;&nbsp;</span>Remover Outliers</a></span></li></ul></li><li><span><a href=\"#Feature-Engineering\" data-toc-modified-id=\"Feature-Engineering-4.11\"><span class=\"toc-item-num\">4.11&nbsp;&nbsp;</span>Feature Engineering</a></span><ul class=\"toc-item\"><li><span><a href=\"#Transformacion-de-Variables\" data-toc-modified-id=\"Transformacion-de-Variables-4.11.1\"><span class=\"toc-item-num\">4.11.1&nbsp;&nbsp;</span>Transformacion de Variables</a></span><ul class=\"toc-item\"><li><span><a href=\"#Normalizacion\" data-toc-modified-id=\"Normalizacion-4.11.1.1\"><span class=\"toc-item-num\">4.11.1.1&nbsp;&nbsp;</span>Normalizacion</a></span></li><li><span><a href=\"#Escalamiento\" data-toc-modified-id=\"Escalamiento-4.11.1.2\"><span class=\"toc-item-num\">4.11.1.2&nbsp;&nbsp;</span>Escalamiento</a></span></li><li><span><a href=\"#Logaritmica\" data-toc-modified-id=\"Logaritmica-4.11.1.3\"><span class=\"toc-item-num\">4.11.1.3&nbsp;&nbsp;</span>Logaritmica</a></span></li><li><span><a href=\"#raíz-cuadrada-/-cúbica\" data-toc-modified-id=\"raíz-cuadrada-/-cúbica-4.11.1.4\"><span class=\"toc-item-num\">4.11.1.4&nbsp;&nbsp;</span>raíz cuadrada / cúbica</a></span></li><li><span><a href=\"#Binning-,-Cambios-de-Numericas-a-Categoricas\" data-toc-modified-id=\"Binning-,-Cambios-de-Numericas-a-Categoricas-4.11.1.5\"><span class=\"toc-item-num\">4.11.1.5&nbsp;&nbsp;</span>Binning , Cambios de Numericas a Categoricas</a></span></li></ul></li></ul></li><li><span><a href=\"#Analisis-Univariable-y-Bivariable-Final\" data-toc-modified-id=\"Analisis-Univariable-y-Bivariable-Final-4.12\"><span class=\"toc-item-num\">4.12&nbsp;&nbsp;</span>Analisis Univariable y Bivariable Final</a></span><ul class=\"toc-item\"><li><span><a href=\"#Creacion-de-Variables\" data-toc-modified-id=\"Creacion-de-Variables-4.12.1\"><span class=\"toc-item-num\">4.12.1&nbsp;&nbsp;</span>Creacion de Variables</a></span><ul class=\"toc-item\"><li><span><a href=\"#Crear-Variables-derivadas-de-Otras\" data-toc-modified-id=\"Crear-Variables-derivadas-de-Otras-4.12.1.1\"><span class=\"toc-item-num\">4.12.1.1&nbsp;&nbsp;</span>Crear Variables derivadas de Otras</a></span></li><li><span><a href=\"#Crear-Variables-de-Categorico-a-Numerico\" data-toc-modified-id=\"Crear-Variables-de-Categorico-a-Numerico-4.12.1.2\"><span class=\"toc-item-num\">4.12.1.2&nbsp;&nbsp;</span>Crear Variables de Categorico a Numerico</a></span></li></ul></li></ul></li><li><span><a href=\"#Reduccion-de-Dimensionalidad-y-Seleccion-de-Variables-(PCA)\" data-toc-modified-id=\"Reduccion-de-Dimensionalidad-y-Seleccion-de-Variables-(PCA)-4.13\"><span class=\"toc-item-num\">4.13&nbsp;&nbsp;</span>Reduccion de Dimensionalidad y Seleccion de Variables (PCA)</a></span></li><li><span><a href=\"#Balance-de-datos\" data-toc-modified-id=\"Balance-de-datos-4.14\"><span class=\"toc-item-num\">4.14&nbsp;&nbsp;</span>Balance de datos</a></span></li></ul></li><li><span><a href=\"#MODELAMIENTO-DE-LOS-DATOS-(MACHINE-LEARNING)\" data-toc-modified-id=\"MODELAMIENTO-DE-LOS-DATOS-(MACHINE-LEARNING)-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>MODELAMIENTO DE LOS DATOS (MACHINE LEARNING)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dividir-el-dataset-en-Training-set-y-Test-set\" data-toc-modified-id=\"Dividir-el-dataset-en-Training-set-y-Test-set-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Dividir el dataset en Training set y Test set</a></span></li></ul></li><li><span><a href=\"#Validacion-y-Evaluacion-Cruzada-(k-fold-Cross-Validation)\" data-toc-modified-id=\"Validacion-y-Evaluacion-Cruzada-(k-fold-Cross-Validation)-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Validacion y Evaluacion Cruzada (k-fold Cross Validation)</a></span></li><li><span><a href=\"#Optimizacion-de-Hiper-parametros-(Hyper-Parameter-optimization)\" data-toc-modified-id=\"Optimizacion-de-Hiper-parametros-(Hyper-Parameter-optimization)-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Optimizacion de Hiper parametros (Hyper Parameter optimization)</a></span></li><li><span><a href=\"#Evaluacion-final-del-modelo-con-el-Test-set\" data-toc-modified-id=\"Evaluacion-final-del-modelo-con-el-Test-set-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Evaluacion final del modelo con el Test set</a></span></li><li><span><a href=\"#Implementacion-del-Modelo-(Deploying)\" data-toc-modified-id=\"Implementacion-del-Modelo-(Deploying)-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Implementacion del Modelo (Deploying)</a></span></li><li><span><a href=\"#Comunicacion-de-Resultados-(Data-Story-Telling)\" data-toc-modified-id=\"Comunicacion-de-Resultados-(Data-Story-Telling)-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Comunicacion de Resultados (Data Story Telling)</a></span></li><li><span><a href=\"#Conclusiones\" data-toc-modified-id=\"Conclusiones-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Conclusiones</a></span></li><li><span><a href=\"#Ayudas-Y-Referencias\" data-toc-modified-id=\"Ayudas-Y-Referencias-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>Ayudas Y Referencias</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo del Trabajo <a class=\"tocSkip\">\n",
    "El objetivo inicial del trabajo es utilizar Python para el procesamiento, descripcion  y visualización de datos, con el fin de dejar los datos preparados para ser usados con algoritmos de Machine Learning para Regresión o Clasificación como objetivo final del trabajo.\n",
    "\n",
    "El trabajo se realizara en Python usando un jupyter notebook o un Notebook de Google Collaboratory, llenando los campos de este archivo y subirlo a github.\n",
    "\n",
    "## Las actividades a realizar<a class=\"tocSkip\">\n",
    "    \n",
    "    \n",
    "1) Preparar los datos, hacer cada uno de los pasos solo si es necesario:\n",
    "      \n",
    "    - Poner los datos en sus tipos de datos correctos\n",
    "    - Remover los valores duplicados\n",
    "    - Procesar y Reemplazar los datos que faltan (Missing N.A values)\n",
    "    - Manejo de outliers\n",
    "    - Re-escalar las variables\n",
    "    - Normalizar\n",
    "    - Data Binning\n",
    "        - Conversión Numérico a categórico\n",
    "        - Conversión Categórico a Numérico\n",
    "\n",
    "2) Realizar una exploración estadística y con visualización de los datos\n",
    "    - Scatter plots\n",
    "    - Histogramas\n",
    "    - boxplot, o las gráficas que considere necesarias\n",
    "\n",
    "\n",
    "3) Entrene y Evalue modelos de Machine Learning según sea su problema, recuerde usar k-fold cross-validation para evitar over fitting, algunos algoritmos recomendados\n",
    "\n",
    "    (a) PREDICCIÓN:\n",
    "    \n",
    "            ▪ Regresión Lineal\n",
    "            ▪ Lasso\n",
    "            ▪ Ridge\n",
    "            ▪ Decision Tree regressor\n",
    "            ▪ Random Forest regressor\n",
    "            ▪ SVR\n",
    "            ▪ KNR\n",
    "            ▪ catboost regressor\n",
    "            \n",
    "    \n",
    "    \n",
    "    (b) CLASIFICACION\n",
    "      \n",
    "            ▪ Regresión Logística\n",
    "            ▪ LinearSVC\n",
    "            ▪ KernelSVC\n",
    "            ▪ Decision Tree clasifier\n",
    "            ▪ Random Forest classifier\n",
    "            ▪ K-NN\n",
    "            ▪ GaussianNB\n",
    "            ▪ catboost\n",
    "    \n",
    "**Nota: utilizar visualizaciones para comunicar los resultados obtenidos.**    \n",
    "            \n",
    "4) Realizar hyperparameter optimization  de los dos métodos que tengan mejor resultado en los pasos anteriores para mejorar el desempeño obtenido. (Tenga en cuenta, que realizar el hyperparameter tuning no garantiza una mejora significativa en el desempeño, pero es bueno intentarlo)\n",
    "    \n",
    "5) Realizar comentarios de cada paso que va realizando en el documento y finalmente también agregue **conclusiones** de:\n",
    "    \n",
    "    - los datos procesados\n",
    "    - la información que observa\n",
    "    - Comparación de la evaluación de los Métodos\n",
    "    - Cual fue el mejor modelo que obtuvo luego de la hiper parametrización\n",
    "    \n",
    "    \n",
    "*NOTA: No dude en contactarme para cualquier pregunta o inquietud :)\n",
    "\n",
    "## FORMATO DE ENTREGA  <a class=\"tocSkip\">\n",
    "\n",
    "EL jupyter notebook estara alojado en un repositorio de Github\n",
    "\n",
    "El código debe tener comentarios y explicaciones de la solución del trabajo.\n",
    "\n",
    "\n",
    "## EVALUACION <a class=\"tocSkip\">\n",
    "(33 % ) preparacion, descripcion y visualizacion de datos\n",
    "    \n",
    "(33 % ) Machine Learning, hiperparametrizacion y Conclusiones\n",
    "    \n",
    "\n",
    "|Porcentaje en la evaluación | Descripción| Nada | Incompleto | Completo |\n",
    "| :---: |:---: |:---: |:---: |:---: |\n",
    "| 11 % |**Preparación de los datos** <br> (datos nulos, outliers, duplicados, <br> corrección de formatos de tipos de datos) |\n",
    "|11 % | **Visualización de datos** <br> (Univarible y Bivariable) <br> Histogramas, boxplots, correlaciones, etc|\n",
    "|11 % | **Descripción y Análisis Estadístico de los datos** |\n",
    "|11 % | **Machine Learning** <br> Entrenar y evaluar todos los modelos propuestos |\n",
    "|11 % | **Hiper parametrizacion** <br> Hiperparametrizar 2 modelos y escoger el mejor modelo |   \n",
    "|11 % | **Resultados y Conclusiones** <br> analisis de los datos, conclusiones del modelos y los resultados obtenidos|\n",
    "\n",
    "\n",
    "Ejemplos y links de ayuda al final del documento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XE2q_0ARHJoM"
   },
   "source": [
    "# Definir el Problema a Resolver\n",
    "\n",
    "El dataset \"house data\", inicialmente se realizará una exploración de datos, para poder saber la calidad del dataset, iniciando con una limpieza la cual consta de eliminar duplicados, identificación de datos atípicos, nullos o mal escritos para poder tratarlos y mitigarlos, ya sea con la eliminación o aplicación de métodos estadísticos, con la finalidad de tener un datset listo y poder aplicar una regresión lineal y poder predecir los precios de venta de una casa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0fWGXusiHJoO"
   },
   "source": [
    "## Describir los datos de entrada y salida\n",
    "- Cantidad de Variables\n",
    "- Tipo de Variables\n",
    "- Significado de cada Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MjPWhesSHJoO"
   },
   "source": [
    "# Importar Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ksQYJRZTHJoP"
   },
   "outputs": [],
   "source": [
    "from jutils.data import DataUtils\n",
    "from jutils.visual import Plot\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas_profiling.profile_report import ProfileReport\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from cache_to_disk import cache_to_disk\n",
    "from IPython.display import display, HTML\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import PowerTransformer, KBinsDiscretizer\n",
    "from scipy import stats\n",
    "import pingouin as pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validar_duplicados(_df):\n",
    "    _filas = _df.shape[0]\n",
    "    _cant_duplicados = _df.duplicated().sum()\n",
    "    print(f'De {_filas} registros hay {_cant_duplicados} filas duplicadas, representando el {_cant_duplicados/_filas:.2%}')\n",
    "\n",
    "def eliminar_duplicados(_df):\n",
    "    # Eliminando duplicados\n",
    "    _df = _df.drop_duplicates(keep='first')\n",
    "    _filas = df.shape[0]\n",
    "    print(f'Después de la eliminación de duplicados, el conjunto de datos queda con {_filas} filas.')\n",
    "    return _df\n",
    "\n",
    "def validar_index_duplicados(_df):\n",
    "    # Validando duplicados de index\n",
    "    _son_duplicados = _df['index'].duplicated()\n",
    "    _cant_duplicados = _son_duplicados.sum()\n",
    "    _filas = _df.shape[0]\n",
    "    print(f'De {_filas} registros, hay {_cant_duplicados} registros con index duplicado, que representan el {_cant_duplicados/_filas:.2%}.')\n",
    "    return _son_duplicados\n",
    "\n",
    "@cache_to_disk(1)\n",
    "def profiler_to_file(_profiler, archivo):\n",
    "    print('Ejecutando profiler')\n",
    "    _profiler.to_file(du.data_folder_path.parent.joinpath('reports/' + archivo))\n",
    "    return True\n",
    "\n",
    "def calcular_descriptivas(_df):\n",
    "    descriptivas = _df.describe()\n",
    "    descriptivas.loc['rango'] = descriptivas.loc['max'] - descriptivas.loc['min']\n",
    "    descriptivas.loc['IQR'] = descriptivas.loc['75%'] - descriptivas.loc['25%']\n",
    "    descriptivas.loc['coef de var'] = descriptivas.loc['std']/descriptivas.loc['mean']\n",
    "    descriptivas.loc['skewness'] = du.data.skew(numeric_only=True)\n",
    "    descriptivas.loc['kurtosis'] = du.data.kurtosis(numeric_only=True)\n",
    "    return descriptivas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LM4dC7lBHJoT"
   },
   "source": [
    "# Cargar Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R2C-zrtBHJoT"
   },
   "outputs": [],
   "source": [
    "du = DataUtils(\n",
    "    Path(r'..\\data').resolve().absolute(),\n",
    "    \"kc_house_dataDS.parquet\",\n",
    "    lambda path: pd.read_parquet(path),\n",
    "    lambda df, path: df.to_parquet(path)\n",
    ")\n",
    "du.data = du.load_data(du.interim_path.joinpath(du.input_file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descripcion General del Dataset\n",
    "- numero de filas y columnas\n",
    "- tipos de datos y si estan correctos\n",
    "\n",
    "Durante la exploración inicial se realizó la conversión de los tipos de datos, y la correcta representación de datos nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = du.data.shape\n",
    "filas = shape[0]\n",
    "columnas = shape[1]\n",
    "print(f'El conjunto de datos se compone de {filas} filas y {columnas} columnas.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "du.data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas las columnas son del tipo correcto a excepción de date, se deberá hacer la conversión de este campo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza de calidad de datos general\n",
    "- Filas con valores exactamente iguales (duplicados)\n",
    "- Columnas duplicadas\n",
    "- Columnas con valores constantes o sin informacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validar_duplicados(du.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "du.data = eliminar_duplicados(du.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validar indices duplicados\n",
    "son_duplicados = validar_index_duplicados(du.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisando los primeros registros duplicados\n",
    "du.data[son_duplicados].sort_values(by='index').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisando los registros duplicados por index, se encuentra que muchas columnas tienen los mismos valores , lo único que cambia es que hay algunos faltantes y hay otros valores extremadamente bajos o altos, adicionalmente se observan algunos registros de la columna date que no son fechas. Primero se convertirá los valores de la columna date a date y los que no puedan ser convertidos se reemplazarán por valores nulos, luego se reemplazarán los valores extremos por valores nulos, luego se calculará la mediana por index para las columnas numéricas y se reemplazarán los valores nulos por estas medianas. Luego se eliminarán filas duplicadas y se reevaluarán los index duplicados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convirtiendo la columna date a datetime\n",
    "du.data['date'] = pd.to_datetime(du.data['date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazando valores extremos, menores a -1e+10 o mayores a 1e+10\n",
    "columnas_numericas = [columna for columna in du.data.columns if columna != 'date']\n",
    "du.data[columnas_numericas] = du.data[columnas_numericas].where(lambda x: x > -1e+10, other=np.nan).where(lambda x: x < 1e+10, other=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se reemplazan los valores extremos por la media\n",
    "for columna_numerica in columnas_numericas:\n",
    "    du.data[columna_numerica]=du.data[columna_numerica].fillna(du.data.groupby('index')[columna_numerica].transform('median'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazando fechas nulas por la primera fecha no nula\n",
    "du.data['date'] = du.data['date'].fillna(du.data.groupby(['index'], sort=False)['date'].apply(lambda x: x.ffill().bfill()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para las siguientes columnas, un cero representa un dato nulo, por lo tanto se reemplazarán.\n",
    "- sqft_basement\n",
    "- yr_renovated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazando ceros por valores nulos\n",
    "du.data[['sqft_basement', 'yr_renovated']] = du.data[['sqft_basement', 'yr_renovated']].replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validar_duplicados(du.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "du.data = eliminar_duplicados(du.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "son_duplicados = validar_index_duplicados(du.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validando columnas con valores constantes\n",
    "unicos=du.data.nunique()\n",
    "unicos[unicos==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La columna wertyj tiene valores constantes, por lo tanto se eliminará."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "du.data.drop(columns=list(unicos[unicos==1].index), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulos = du.data.isnull().sum()\n",
    "porce = nulos/filas\n",
    "nulos = pd.DataFrame({'nulos':nulos, 'porc':porce})\n",
    "# Se contarán las filas que contengan algún dato nulo\n",
    "al_menos_un_nulo=du.data.isnull().any(axis=1).sum()\n",
    "nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'De {filas} registros, hay {al_menos_un_nulo} registros con al menos un valor nulo, representando el {al_menos_un_nulo/filas:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividir el dataset en Training set y Test set\n",
    "\n",
    "Este paso debe ser al inicio de los proyectos,  Se deben realizar todas las transformaciones, preparación de datos y limpieza de los datos, en el train set y en la evaluacion se deben aplicarl al test set y a los datos nuevos que lleguen al sistema. Esta division inicial se hace para evitar data leakage de los datos de test a los datos de train, por ejemplo en las imputaciones.\n",
    "\n",
    "Por este motivo se realizara en esta parte.\n",
    "\n",
    "Division de los datos de entrenamiento (Train set) y de Evaluacion (test - set), las divisiones utilizadas son\n",
    "\n",
    "- 80% (train) , 20%(test)\n",
    "- 70% (train) , 30%(test)\n",
    "\n",
    "El **Train set** se hace para seleccion de Modelos y el **Test-set** solamente para la evaluacion Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test, validation = train_test_split(du.data, test_size=0.8, random_state=1)\n",
    "du.save_data(train_test, du.raw_train_test_path)\n",
    "du.save_data(validation, du.raw_validation_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5gnmm4vdHJoV"
   },
   "source": [
    "# Descripcion  y Limpieza de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZYzna68bHJoW"
   },
   "outputs": [],
   "source": [
    "du.data = du.load_data(du.raw_train_test_path)\n",
    "print('Tipos de variables')\n",
    "du.data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AFSKQY4Amzwv"
   },
   "source": [
    "## Identificacion de Variables\n",
    "- Variables de entrada y de salida\n",
    "- Tipo de Variables (categoricas o Numericas)\n",
    "- Tipo de datos (int, float, string, factor, boolean, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bnXkopIFHJob"
   },
   "outputs": [],
   "source": [
    "columnas_no_entrada = {'date', 'index'}\n",
    "entradas = [column for column in du.data.columns if column not in columnas_no_entrada]\n",
    "print('Columnas de entrada:')\n",
    "print(', '.join(entradas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salida = 'date'\n",
    "print(f'Columna de salida: {salida}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisis General Univariable y Bivariable \n",
    "Analisis de cada una de las variables para lograr calidad de datos en cada columna\n",
    "- **Correccion del tipo de dato (numericas, categoricas, string) de cada columna (optimizar memoria)**\n",
    "- Deteccion de numero de datos faltantes\n",
    "- Deteccion de duplicados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k5CEar_Cnw2x"
   },
   "source": [
    "## Eliminar columnas de datos Innecesarios\n",
    "\n",
    "Se realizará un perfilado de los datos para identificar problemas de calidad no identificados anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bxoNbnANoJt8"
   },
   "outputs": [],
   "source": [
    "columnas_entrenamiento = entradas + [salida]\n",
    "profiler = ProfileReport(du.data[columnas_entrenamiento], explorative=True)\n",
    "\n",
    "profiler_to_file(profiler, '1_0.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficar = Plot()\n",
    "graficar.box(du.data, y='sqft_lot15')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Columna       | Tipo               | Problemas de calidad encontrados  | Correcciones                                                                                                                                                                                                                                                                                                                                                              |\n",
    "|---------------|--------------------|-----------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| df_index      |                    |                                   |                                                                                                                                                                                                                                                                                                                                                                           |\n",
    "| zipcode       |                    |                                   | Se eliminará                                                                                                                                                                                                                                                                                                                                                              |\n",
    "| grade         | Categórica         |                                   |                                                                                                                                                                                                                                                                                                                                                                           |\n",
    "| sqft_basement | Numérica           | Muchos datos nulos                | Se encontró el 60.8% nulos, se transformará esta columna en una columna categórica binaria que diga si tiene sótano o no (Si el valor es nulo no tiene, de lo contrario si tiene).                                                                                                                                                                                        |\n",
    "| view          | Categórica         |                                   |                                                                                                                                                                                                                                                                                                                                                                           |\n",
    "| bathrooms     | Numérica           |                                   |                                                                                                                                                                                                                                                                                                                                                                           |\n",
    "| bedrooms      | Numérica           |                                   |                                                                                                                                                                                                                                                                                                                                                                           |\n",
    "| sqft_above    | Numérica           | Tiene una distribución asimétrica | Se transformará para normalizar la distribución.                                                                                                                                                                                                                                                                                                                          |\n",
    "| sqft_living15 | Numérica           | Tiene una distribución asimétrica | Se transformará para normalizar la distribución.                                                                                                                                                                                                                                                                                                                          |\n",
    "| lat           |                    |                                   | Se eliminará, esta columna solo representa una posición, y como todas las casas están en la misma ciudad, es la misma latitud.                                                                                                                                                                                                                                            |\n",
    "| waterfront    | Categórica         |                                   |                                                                                                                                                                                                                                                                                                                                                                           |\n",
    "| floors        | Numérica           |                                   |                                                                                                                                                                                                                                                                                                                                                                           |\n",
    "| date          | fecha              |                                   | Se utilizará esta columna para calcular la cantidad de años transcurridos desde la construcción de la propiedad hasta la venta de la misma.                                                                                                                                                                                                                               |\n",
    "| yr_renovated  | Numérica           |                                   | Se eliminará, será reemplazada por una columna que indique si fue renovada o no sin importar el año.                                                                                                                                                                                                                                                                      |\n",
    "| yr_built      |                    |                                   | Se utilizará para calcular los años transcurridos desde la construcción hasta la venta de la propiedad, luego será eliminada.                                                                                                                                                                                                                                             |\n",
    "| long          |                    |                                   | Se eliminará, esta columna solo representa una posición, y como todas las casas están en la misma ciudad, es la misma longitud.                                                                                                                                                                                                                                           |\n",
    "| jhygtf        |                    |                                   | Es la misma columna que yr_renovated, será eliminada.                                                                                                                                                                                                                                                                                                                     |\n",
    "| sqft_lot      | Numérica           | Se encontraron datos atípicos.    | Se encontró que el dato mas grande es de 1 millón de pies cuadrados que equivalen a aproximadamente 10 hectáreas, se considera que una propiedad puede tener estas dimensiones, por lo tanto no se considera un error. Se aplicará logaritmo y se validará si la distribución se normaliza, de lo contrario, se convertirá a categórica dividiéndola en rangos de tamaño. |\n",
    "| price         | Numérica           | Tiene una distribución asimétrica | Se transformará para normalizar la distribución.                                                                                                                                                                                                                                                                                                                          |\n",
    "| condition     | Categórica nominal |                                   | Se aplicará one hot encoding                                                                                                                                                                                                                                                                                                                                              |\n",
    "| sqft_lot15    | Numérica           | Tiene una distribución asimétrica | Se transformará para normalizar la distribución.                                                                                                                                                                                                                                                                                                                          |\n",
    "| sqft_living   | Numérica           | Tiene una distribución asimétrica | Se transformará para normalizar la distribución.                                                                                                                                                                                                                                                                                                                          |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversión tipos de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_categoricas = ['grade', 'view', 'waterfront', 'condition']\n",
    "du.data[variables_categoricas] = du.data[variables_categoricas].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculo de variables adicionales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Años transcurridos entre la construcción de la vivienda y la venta de la misma columnas yr_built y date\n",
    "# Primero se extraerá el año de la fecha para realizar la resta con yr_built\n",
    "du.data['yr_date'] = du.data['date'].dt.year\n",
    "du.data['antiguedad_venta'] = du.data['yr_date'] - du.data['yr_built']\n",
    "du.data.drop(columns=['yr_date', 'date', 'yr_built'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminación de columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "du.data.drop(columns=['zipcode', 'lat', 'yr_renovated', 'long', 'jhygtf'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_numericas   = ['sqft_basement', 'bathrooms', 'bedrooms', 'sqft_above', 'sqft_living15', 'floors', 'sqft_lot', 'price', 'sqft_lot15',\n",
    "                         'sqft_living', 'antiguedad_venta']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2LmnrQtbHJox"
   },
   "source": [
    "## Procesamiento de Datos Faltantes\n",
    "Las opciones que se pueden usar dependiendo del analisis de los datos son:\n",
    "### Borrar Filas\n",
    "- Borrar las filas que les falten todos los datos\n",
    "- Borrar Solo las filas que les falta las variables mas importantes o la salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zFwqgwOhHJox"
   },
   "outputs": [],
   "source": [
    "columnas_datosFaltantes = [columna for columna in du.data.columns if columna != 'date' and columna !=   'sqft_basement' and columna != 'yr_renovated' ]\n",
    "du.data=du.data.dropna(subset=columnas_datosFaltantes)\n",
    "du.data.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GnkcN0goHJod"
   },
   "source": [
    "## Analisis Univariable\n",
    "\n",
    "Estadistico Descriptico y Analisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LEvH4-LGHJod"
   },
   "source": [
    "### Variables Numericas\n",
    "\n",
    "| Tendencia Central |   Medida de Dispersión    | Visualizacion |\n",
    "|:-----------------:|:-------------------------:|:-------------:|\n",
    "|       Media       |           Rango           |  Histogramas  |\n",
    "|      Mediana      |         Cuartiles         |   Boxplots    |\n",
    "|       Moda        | Rango inter cuartil (IQR) |               |\n",
    "|      Minimo       |         Varianza          |               |\n",
    "|      Maximo       |   Desviacion Estandard    |               |\n",
    "|         .         |         Skewness          |               |\n",
    "|         .         |         Kurtosis          |               |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CDTBsGi0HJoe"
   },
   "outputs": [],
   "source": [
    "calcular_descriptivas(du.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable_numerica in variables_numericas:\n",
    "    graficar.box(du.data, y=variable_numerica).show()\n",
    "\n",
    "for variable_numerica in variables_numericas:\n",
    "    graficar.histogram(du.data, x=variable_numerica, nbins=5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mXQHmtMbHJoh"
   },
   "source": [
    "### Variables Categoricas\n",
    "- Numero de elementos por categoria\n",
    "- Porcentaje de elementos por categoria\n",
    "- Graficos de barras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hPY0sHqNHJoi"
   },
   "outputs": [],
   "source": [
    "resumen = []\n",
    "\n",
    "for variable_categorica in variables_categoricas:\n",
    "    col = du.data[variable_categorica]\n",
    "    elms_cat = col.groupby(by=col).agg('count')\n",
    "    total = elms_cat.sum()\n",
    "    porc = elms_cat / total\n",
    "    porc.name = 'porc'\n",
    "    df = pd.DataFrame([elms_cat, porc]).transpose()\n",
    "    resumen.append(df)\n",
    "\n",
    "for tabla in resumen:\n",
    "    display(HTML(tabla.to_html()))\n",
    "    variable = tabla.columns[0]\n",
    "    fig = px.bar(tabla[variable], orientation='h', title=str(variable))\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jmf_f9TOHJok"
   },
   "source": [
    "## Analisis Bivariable\n",
    "Estadistico Descriptico y Analisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3aVUkwJVHJom"
   },
   "source": [
    "### Numericas vs Numericas\n",
    "- Scatter Plot\n",
    "- Heatmap\n",
    "- Correlacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "067r3JdGHJon"
   },
   "outputs": [],
   "source": [
    "corr_matrix = du.data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix['price'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las variables relacionadas con el tamaño del apartamento tienen mayor correlación con el precio del apartamento, se observa que la antiguedad de venta, no tiene correlación con el precio, por lo tanto esta columna será eliminada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "du.data.drop(columns='antiguedad_venta', inplace=True)\n",
    "# plot it\n",
    "sns.heatmap(corr_matrix, cmap='PuOr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T544jyPsHJos"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "plt.scatter(du.data['price'], du.data['bedrooms'])\n",
    "\n",
    "plt.xlabel('precio')\n",
    "plt.ylabel('cantidad de baños')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficar.scatter(du.data,x='price',y='sqft_lot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se pueden resaltar dos datos atípicos, una casa muy económica y grande (USD 937000 y 871000 sqft) y una casa muy costosa y pequeña (USD 3000000000 y 19897 sqft), estos datos se consideran atípicos pero que pueden ocurrir en la realidad. Adicionalmente se encuentran dos grupos de apartamentos, el primer grupo son casas que cuestan menos de 8 millones y tienen áreas hasta de alrededor de 1 millón de pies cuadrados, unas 10 hectáreas. El otro grupo son casas entre 1000 millones y 3000 millones con áreas hasta de 0.2 millónes de pies cuadrados, unas 2 hectáreas. Inicialmente se construirá un primer modelo con ambos grupos juntos, y se evaluará su desempeño."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s4Fn2YIvHJpL"
   },
   "source": [
    "## Feature Engineering \n",
    "### Transformacion de Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario donde se almacenaran los transformadores\n",
    "transformers = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jYPdefrhHJpS"
   },
   "source": [
    "#### Logaritmica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wU-lW1AQHJpS"
   },
   "outputs": [],
   "source": [
    "# Se transformarán las siguientes variables: sqft_above, sqft_living15, sqft_lot, price, sqft_lot15, sqft_living\n",
    "columnas = ['sqft_above', 'sqft_living15', 'sqft_lot', 'price', 'sqft_lot15', 'sqft_living']\n",
    "pt = PowerTransformer()\n",
    "pt.fit(du.data[columnas])\n",
    "transformers['PowerTransformer'] = pt\n",
    "du.data[columnas] = pt.transform(du.data[columnas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "profiler2 = ProfileReport(du.data[columnas], explorative=True)\n",
    "profiler_to_file(profiler2, 'power_transform.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se revisará nuevamente la distribución de las variables con box plots e histogramas\n",
    "for variable_numerica in columnas:\n",
    "    graficar.box(du.data[columnas], y=variable_numerica).show()\n",
    "\n",
    "for variable_numerica in columnas:\n",
    "    graficar.histogram(du.data[columnas], x=variable_numerica, nbins=20).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calcular_descriptivas(du.data[columnas])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de realizar la transformación de las variables, se encuentra que sqft_lot y sqft_lot15 siguen teniendo una alta kurtosis, por lo tanto se procederá a convertirlas en variables categóricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_a_categoricas = ['sqft_lot', 'sqft_lot15']\n",
    "kbd = KBinsDiscretizer(strategy='kmeans', encode='ordinal')\n",
    "kbd.fit(du.data[columnas_a_categoricas])\n",
    "transformers['KBinsDiscretizer'] = kbd\n",
    "du.data[columnas_a_categoricas] = kbd.transform(du.data[columnas_a_categoricas])\n",
    "du.data[columnas_a_categoricas] = du.data[columnas_a_categoricas].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I6PpnSEDHJpY"
   },
   "source": [
    "## Analisis Univariable y Bivariable Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiler3 = ProfileReport(du.data, explorative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiler_to_file(profiler3, '2_0_transformacion_final.html')\n",
    "profiler3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= du.data[['grade','view','condition']]\n",
    "sns.distplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uRwep7LjHJpZ"
   },
   "source": [
    "### Creacion de Variables\n",
    "pueden ser:\n",
    "#### Crear Variables derivadas de Otras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JCcM4XFbHJpd"
   },
   "source": [
    "#### Crear Variables de Categorico a Numerico\n",
    "Puede ser\n",
    "- Definir un numero a cada categoria\n",
    "- One hot encoder (dummy columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELAMIENTO DE LOS DATOS (MACHINE LEARNING)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validacion y Evaluacion Cruzada (k-fold Cross Validation)\n",
    "\n",
    "Se hace seleccion de los mejores modelos usando el Training Set y k-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizacion de Hiper parametros (Hyper Parameter optimization)\n",
    "\n",
    "Se seleccionan solo los mejores modelos para realizar el ajuste de hiperparametros, ya que tiene una carga computacional alta.\n",
    "\n",
    "Al final se obtienen los parametros del mejor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluacion final del modelo con el Test set\n",
    "\n",
    "Tomar los parametros obtenidos en el paso anterior, se crea el modelo con esos pararmetros y se entrena el modelo con todos los datos del **Train -set**\n",
    "\n",
    "Finalmente se realiza la evaluacion (segun su problema si es de regresion o de clasificacion) usando el **Test - set** para definir si el modelo obtenido esta bien. Compare los resultados con el **Train -set** vs los resultados con el **Test - set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementacion del Modelo (Deploying)\n",
    "Con el análisis básico y el ajuste hecho, comienza el trabajo real (ingeniería).\n",
    "\n",
    "El último paso para poner en produccion el modelo de prediccion sera:\n",
    "1. Entrenarlo en todo el conjunto de datos nuevamente, para hacer un uso completo de todos los datos disponibles. \n",
    "2. Usar los mejores parámetros encontrados mediante la validación cruzada, por supuesto. Esto es muy similar a lo que hicimos al principio, pero esta vez teniendo una idea de su comportamiento y estabilidad. La evaluación se realizó con honestidad, en divisiones distintas de entrenamiento / prueba.\n",
    "\n",
    "El predictor final se puede serializar y grabar en el disco, de modo que la próxima vez que lo usemos, podemos omitir todo el entrenamiento y usar el modelo capacitado directamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle # Esta es una libreria de serializacion nativa de python, puede tener problemas de seguridad\n",
    "from joblib import dump # libreria de serializacion\n",
    "\n",
    "# garbar el modelo en un archivo\n",
    "#dump(Modelo_final, 'Nombre_Archivo_Modelo.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comunicacion de Resultados (Data Story Telling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ayudas Y Referencias\n",
    "\n",
    "- https://medium.com/@joserzapata/paso-a-paso-en-un-proyecto-machine-learning-bcdd0939d387\n",
    "- [Proyecto de Principio a Final sobre readmision de pacientes con Diabetes](https://github.com/JoseRZapata/Readmission-ML-Project)\n",
    "\n",
    "- [a-complete-machine-learning-walk-through-in-python-part-one](https://towardsdatascience.com/a-complete-machine-learning-walk-through-in-python-part-one-c62152f39420)\n",
    "\n",
    "\n",
    "- [a-starter-pack-to-exploratory-data-analysis-with-python-pandas-seaborn-and-scikit-learn](https://towardsdatascience.com/a-starter-pack-to-exploratory-data-analysis-with-python-pandas-seaborn-and-scikit-learn-a77889485baf#249d)\n",
    "\n",
    "- [a-data-science-for-good-machine-learning-project-walk-through-in-python-part-one](https://towardsdatascience.com/a-data-science-for-good-machine-learning-project-walk-through-in-python-part-one-1977dd701dbc)\n",
    "\n",
    "- [Ejemplos de Kaggle](https://www.kaggle.com/kernels?sortBy=hotness&group=everyone&pageSize=20&language=Python&kernelType=Notebook)\n",
    "\n",
    "- [END to END ML from data colletion to deployment](https://medium.com/datadriveninvestor/end-to-end-machine-learning-from-data-collection-to-deployment-ce74f51ca203)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docente: [Jose R. Zapata](https://joserzapata.github.io)\n",
    "- https://joserzapata.github.io\n",
    "- https://twitter.com/joserzapata\n",
    "- https://www.linkedin.com/in/jose-ricardo-zapata-gonzalez/   "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "mXQHmtMbHJoh",
    "3aVUkwJVHJom",
    "9SfZHh6oHJor",
    "1S_iRK8rHJo0",
    "Ey5Lk8evHJo3",
    "0Y0UV-GVHJo6",
    "he4lxsEUHJpM",
    "h0FKIrJHHJpO",
    "jYPdefrhHJpS",
    "zUundEM6HJpT",
    "2GNrgJzHHJpW",
    "uRwep7LjHJpZ",
    "JCcM4XFbHJpd"
   ],
   "name": "Trabajo_Preparacion_Datos_JoseR_Zapata.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "nbTranslate": {
   "displayLangs": [
    "es",
    "en"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "es",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Contenido",
   "title_sidebar": "Contenido",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "447c0f0993c7e50bc10ddc9bd7e362220c6ef046a7e5a6eb2fbe70cad79928d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
