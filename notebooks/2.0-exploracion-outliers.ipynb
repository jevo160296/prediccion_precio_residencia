{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wbepu01LHJoL"
   },
   "source": [
    "# Trabajo Preparacion, visualizacion de Datos y Machine learning con Python<a class=\"tocSkip\">\n",
    "## Ciencia de datos en Produccion <a class=\"tocSkip\">\n",
    "\n",
    "**Estudiante:** Sebastián Cardona y Jose Miguel Millán\n",
    "\n",
    "**ID:** 1094910122 y 1088334182\n",
    "\n",
    "**Email:** sacardonar@uqvirtual.edu.co y josem.millanl@uqvirtual.edu.co\n",
    "\n",
    " \n",
    "**Ponga su nombre en el archivo de Jupyter Notebook \n",
    "Docente: [Jose R. Zapata](https://joserzapata.github.io)\n",
    "- https://joserzapata.github.io\n",
    "- https://twitter.com/joserzapata\n",
    "- https://www.linkedin.com/in/jose-ricardo-zapata-gonzalez/       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s_RCEnM3HJoL",
    "toc": true
   },
   "source": [
    "<h1>Contenido<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Definir-el-Problema-a-Resolver\" data-toc-modified-id=\"Definir-el-Problema-a-Resolver-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Definir el Problema a Resolver</a></span><ul class=\"toc-item\"><li><span><a href=\"#Describir-los-datos-de-entrada-y-salida\" data-toc-modified-id=\"Describir-los-datos-de-entrada-y-salida-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Describir los datos de entrada y salida</a></span></li></ul></li><li><span><a href=\"#Importar-Librerias\" data-toc-modified-id=\"Importar-Librerias-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Importar Librerias</a></span></li><li><span><a href=\"#Cargar-Datasets\" data-toc-modified-id=\"Cargar-Datasets-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Cargar Datasets</a></span></li><li><span><a href=\"#Descripcion--y-Limpieza-de-los-datos\" data-toc-modified-id=\"Descripcion--y-Limpieza-de-los-datos-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Descripcion  y Limpieza de los datos</a></span><ul class=\"toc-item\"><li><span><a href=\"#Identificacion-de-Variables\" data-toc-modified-id=\"Identificacion-de-Variables-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Identificacion de Variables</a></span></li><li><span><a href=\"#Analisis-General-Univariable-y-Bivariable\" data-toc-modified-id=\"Analisis-General-Univariable-y-Bivariable-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Analisis General Univariable y Bivariable</a></span></li><li><span><a href=\"#Eliminar-columnas-de-datos-Innecesarios\" data-toc-modified-id=\"Eliminar-columnas-de-datos-Innecesarios-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Eliminar columnas de datos Innecesarios</a></span></li><li><span><a href=\"#Remover-Datos-Duplicados-Exactos\" data-toc-modified-id=\"Remover-Datos-Duplicados-Exactos-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Remover Datos Duplicados Exactos</a></span></li><li><span><a href=\"#Procesamiento-de-Datos-Faltantes\" data-toc-modified-id=\"Procesamiento-de-Datos-Faltantes-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Procesamiento de Datos Faltantes</a></span><ul class=\"toc-item\"><li><span><a href=\"#Borrar-Filas\" data-toc-modified-id=\"Borrar-Filas-4.5.1\"><span class=\"toc-item-num\">4.5.1&nbsp;&nbsp;</span>Borrar Filas</a></span></li><li><span><a href=\"#Reemplazar-datos-faltantes-con-la-Media/-Moda/-Mediana-(Mean/-Mode/-Median-Imputation)\" data-toc-modified-id=\"Reemplazar-datos-faltantes-con-la-Media/-Moda/-Mediana-(Mean/-Mode/-Median-Imputation)-4.5.2\"><span class=\"toc-item-num\">4.5.2&nbsp;&nbsp;</span>Reemplazar datos faltantes con la Media/ Moda/ Mediana (Mean/ Mode/ Median Imputation)</a></span></li></ul></li><li><span><a href=\"#Remover-Datos-Duplicados-Exactos\" data-toc-modified-id=\"Remover-Datos-Duplicados-Exactos-4.6\"><span class=\"toc-item-num\">4.6&nbsp;&nbsp;</span>Remover Datos Duplicados Exactos</a></span></li><li><span><a href=\"#Analisis-Univariable\" data-toc-modified-id=\"Analisis-Univariable-4.7\"><span class=\"toc-item-num\">4.7&nbsp;&nbsp;</span>Analisis Univariable</a></span><ul class=\"toc-item\"><li><span><a href=\"#Variables-Numericas\" data-toc-modified-id=\"Variables-Numericas-4.7.1\"><span class=\"toc-item-num\">4.7.1&nbsp;&nbsp;</span>Variables Numericas</a></span></li><li><span><a href=\"#Variables-Categoricas\" data-toc-modified-id=\"Variables-Categoricas-4.7.2\"><span class=\"toc-item-num\">4.7.2&nbsp;&nbsp;</span>Variables Categoricas</a></span></li></ul></li><li><span><a href=\"#Analisis-Bivariable\" data-toc-modified-id=\"Analisis-Bivariable-4.8\"><span class=\"toc-item-num\">4.8&nbsp;&nbsp;</span>Analisis Bivariable</a></span><ul class=\"toc-item\"><li><span><a href=\"#Numericas-vs-Numericas\" data-toc-modified-id=\"Numericas-vs-Numericas-4.8.1\"><span class=\"toc-item-num\">4.8.1&nbsp;&nbsp;</span>Numericas vs Numericas</a></span></li><li><span><a href=\"#Categoricas-vs-Categoricas\" data-toc-modified-id=\"Categoricas-vs-Categoricas-4.8.2\"><span class=\"toc-item-num\">4.8.2&nbsp;&nbsp;</span>Categoricas vs Categoricas</a></span></li><li><span><a href=\"#Categoricas-vs-Numericas\" data-toc-modified-id=\"Categoricas-vs-Numericas-4.8.3\"><span class=\"toc-item-num\">4.8.3&nbsp;&nbsp;</span>Categoricas vs Numericas</a></span></li></ul></li><li><span><a href=\"#Procesamiento-de-Outliers\" data-toc-modified-id=\"Procesamiento-de-Outliers-4.9\"><span class=\"toc-item-num\">4.9&nbsp;&nbsp;</span>Procesamiento de Outliers</a></span><ul class=\"toc-item\"><li><span><a href=\"#Deteccion-de-Outliers-(Univariables-y-Bi-variables)\" data-toc-modified-id=\"Deteccion-de-Outliers-(Univariables-y-Bi-variables)-4.9.1\"><span class=\"toc-item-num\">4.9.1&nbsp;&nbsp;</span>Deteccion de Outliers (Univariables y Bi variables)</a></span></li><li><span><a href=\"#Remover-Outliers\" data-toc-modified-id=\"Remover-Outliers-4.9.2\"><span class=\"toc-item-num\">4.9.2&nbsp;&nbsp;</span>Remover Outliers</a></span></li></ul></li><li><span><a href=\"#Procesamiento-de-Outliers\" data-toc-modified-id=\"Procesamiento-de-Outliers-4.10\"><span class=\"toc-item-num\">4.10&nbsp;&nbsp;</span>Procesamiento de Outliers</a></span><ul class=\"toc-item\"><li><span><a href=\"#Deteccion-de-Outliers-(Univariables-y-Bi-variables)\" data-toc-modified-id=\"Deteccion-de-Outliers-(Univariables-y-Bi-variables)-4.10.1\"><span class=\"toc-item-num\">4.10.1&nbsp;&nbsp;</span>Deteccion de Outliers (Univariables y Bi variables)</a></span></li><li><span><a href=\"#Remover-Outliers\" data-toc-modified-id=\"Remover-Outliers-4.10.2\"><span class=\"toc-item-num\">4.10.2&nbsp;&nbsp;</span>Remover Outliers</a></span></li></ul></li><li><span><a href=\"#Feature-Engineering\" data-toc-modified-id=\"Feature-Engineering-4.11\"><span class=\"toc-item-num\">4.11&nbsp;&nbsp;</span>Feature Engineering</a></span><ul class=\"toc-item\"><li><span><a href=\"#Transformacion-de-Variables\" data-toc-modified-id=\"Transformacion-de-Variables-4.11.1\"><span class=\"toc-item-num\">4.11.1&nbsp;&nbsp;</span>Transformacion de Variables</a></span><ul class=\"toc-item\"><li><span><a href=\"#Normalizacion\" data-toc-modified-id=\"Normalizacion-4.11.1.1\"><span class=\"toc-item-num\">4.11.1.1&nbsp;&nbsp;</span>Normalizacion</a></span></li><li><span><a href=\"#Escalamiento\" data-toc-modified-id=\"Escalamiento-4.11.1.2\"><span class=\"toc-item-num\">4.11.1.2&nbsp;&nbsp;</span>Escalamiento</a></span></li><li><span><a href=\"#Logaritmica\" data-toc-modified-id=\"Logaritmica-4.11.1.3\"><span class=\"toc-item-num\">4.11.1.3&nbsp;&nbsp;</span>Logaritmica</a></span></li><li><span><a href=\"#raíz-cuadrada-/-cúbica\" data-toc-modified-id=\"raíz-cuadrada-/-cúbica-4.11.1.4\"><span class=\"toc-item-num\">4.11.1.4&nbsp;&nbsp;</span>raíz cuadrada / cúbica</a></span></li><li><span><a href=\"#Binning-,-Cambios-de-Numericas-a-Categoricas\" data-toc-modified-id=\"Binning-,-Cambios-de-Numericas-a-Categoricas-4.11.1.5\"><span class=\"toc-item-num\">4.11.1.5&nbsp;&nbsp;</span>Binning , Cambios de Numericas a Categoricas</a></span></li></ul></li></ul></li><li><span><a href=\"#Analisis-Univariable-y-Bivariable-Final\" data-toc-modified-id=\"Analisis-Univariable-y-Bivariable-Final-4.12\"><span class=\"toc-item-num\">4.12&nbsp;&nbsp;</span>Analisis Univariable y Bivariable Final</a></span><ul class=\"toc-item\"><li><span><a href=\"#Creacion-de-Variables\" data-toc-modified-id=\"Creacion-de-Variables-4.12.1\"><span class=\"toc-item-num\">4.12.1&nbsp;&nbsp;</span>Creacion de Variables</a></span><ul class=\"toc-item\"><li><span><a href=\"#Crear-Variables-derivadas-de-Otras\" data-toc-modified-id=\"Crear-Variables-derivadas-de-Otras-4.12.1.1\"><span class=\"toc-item-num\">4.12.1.1&nbsp;&nbsp;</span>Crear Variables derivadas de Otras</a></span></li><li><span><a href=\"#Crear-Variables-de-Categorico-a-Numerico\" data-toc-modified-id=\"Crear-Variables-de-Categorico-a-Numerico-4.12.1.2\"><span class=\"toc-item-num\">4.12.1.2&nbsp;&nbsp;</span>Crear Variables de Categorico a Numerico</a></span></li></ul></li></ul></li><li><span><a href=\"#Reduccion-de-Dimensionalidad-y-Seleccion-de-Variables-(PCA)\" data-toc-modified-id=\"Reduccion-de-Dimensionalidad-y-Seleccion-de-Variables-(PCA)-4.13\"><span class=\"toc-item-num\">4.13&nbsp;&nbsp;</span>Reduccion de Dimensionalidad y Seleccion de Variables (PCA)</a></span></li><li><span><a href=\"#Balance-de-datos\" data-toc-modified-id=\"Balance-de-datos-4.14\"><span class=\"toc-item-num\">4.14&nbsp;&nbsp;</span>Balance de datos</a></span></li></ul></li><li><span><a href=\"#MODELAMIENTO-DE-LOS-DATOS-(MACHINE-LEARNING)\" data-toc-modified-id=\"MODELAMIENTO-DE-LOS-DATOS-(MACHINE-LEARNING)-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>MODELAMIENTO DE LOS DATOS (MACHINE LEARNING)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dividir-el-dataset-en-Training-set-y-Test-set\" data-toc-modified-id=\"Dividir-el-dataset-en-Training-set-y-Test-set-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Dividir el dataset en Training set y Test set</a></span></li></ul></li><li><span><a href=\"#Validacion-y-Evaluacion-Cruzada-(k-fold-Cross-Validation)\" data-toc-modified-id=\"Validacion-y-Evaluacion-Cruzada-(k-fold-Cross-Validation)-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Validacion y Evaluacion Cruzada (k-fold Cross Validation)</a></span></li><li><span><a href=\"#Optimizacion-de-Hiper-parametros-(Hyper-Parameter-optimization)\" data-toc-modified-id=\"Optimizacion-de-Hiper-parametros-(Hyper-Parameter-optimization)-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Optimizacion de Hiper parametros (Hyper Parameter optimization)</a></span></li><li><span><a href=\"#Evaluacion-final-del-modelo-con-el-Test-set\" data-toc-modified-id=\"Evaluacion-final-del-modelo-con-el-Test-set-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Evaluacion final del modelo con el Test set</a></span></li><li><span><a href=\"#Implementacion-del-Modelo-(Deploying)\" data-toc-modified-id=\"Implementacion-del-Modelo-(Deploying)-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Implementacion del Modelo (Deploying)</a></span></li><li><span><a href=\"#Comunicacion-de-Resultados-(Data-Story-Telling)\" data-toc-modified-id=\"Comunicacion-de-Resultados-(Data-Story-Telling)-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Comunicacion de Resultados (Data Story Telling)</a></span></li><li><span><a href=\"#Conclusiones\" data-toc-modified-id=\"Conclusiones-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Conclusiones</a></span></li><li><span><a href=\"#Ayudas-Y-Referencias\" data-toc-modified-id=\"Ayudas-Y-Referencias-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>Ayudas Y Referencias</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo del Trabajo <a class=\"tocSkip\">\n",
    "En el anterior experimento se entrenaron dos modelos de regresión considerando unos casos atípicos dentro del análisis, los modelos resultantes tuvieron un bajo desempeño, por lo tanto, en este experimento se eliminarán los datos atípicos encontrados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XE2q_0ARHJoM"
   },
   "source": [
    "# Definir el Problema a Resolver\n",
    "\n",
    "El dataset \"house data\", inicialmente se realizará una exploración de datos, para poder saber la calidad del dataset, iniciando con una limpieza la cual consta de eliminar duplicados, identificación de datos atípicos, nullos o mal escritos para poder tratarlos y mitigarlos, ya sea con la eliminación o aplicación de métodos estadísticos, con la finalidad de tener un datset listo y poder aplicar una regresión lineal y poder predecir los precios de venta de una casa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0fWGXusiHJoO"
   },
   "source": [
    "## Describir los datos de entrada y salida\n",
    "- Cantidad de Variables\n",
    "- Tipo de Variables\n",
    "- Significado de cada Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MjPWhesSHJoO"
   },
   "source": [
    "# Importar Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ksQYJRZTHJoP"
   },
   "outputs": [],
   "source": [
    "from jutils.data import DataUtils\n",
    "from jutils.visual import Plot\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas_profiling.profile_report import ProfileReport\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from cache_to_disk import cache_to_disk\n",
    "from IPython.display import display, HTML\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import PowerTransformer, KBinsDiscretizer, OneHotEncoder\n",
    "from scipy import stats\n",
    "import pingouin as pg\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validar_duplicados(_df):\n",
    "    _filas = _df.shape[0]\n",
    "    _cant_duplicados = _df.duplicated().sum()\n",
    "    print(f'De {_filas} registros hay {_cant_duplicados} filas duplicadas, representando el {_cant_duplicados/_filas:.2%}')\n",
    "\n",
    "def eliminar_duplicados(_df):\n",
    "    # Eliminando duplicados\n",
    "    _df = _df.drop_duplicates(keep='first')\n",
    "    _filas = _df.shape[0]\n",
    "    print(f'Después de la eliminación de duplicados, el conjunto de datos queda con {_filas} filas.')\n",
    "    return _df\n",
    "\n",
    "def validar_index_duplicados(_df):\n",
    "    # Validando duplicados de index\n",
    "    _son_duplicados = _df['index'].duplicated()\n",
    "    _cant_duplicados = _son_duplicados.sum()\n",
    "    _filas = _df.shape[0]\n",
    "    print(f'De {_filas} registros, hay {_cant_duplicados} registros con index duplicado, que representan el {_cant_duplicados/_filas:.2%}.')\n",
    "    return _son_duplicados\n",
    "\n",
    "@cache_to_disk(1)\n",
    "def profiler_to_file(_profiler, archivo):\n",
    "    print('Ejecutando profiler')\n",
    "    _profiler.to_file(du.data_folder_path.parent.joinpath('reports/' + archivo))\n",
    "    return True\n",
    "\n",
    "def calcular_descriptivas(_df):\n",
    "    descriptivas = _df.describe()\n",
    "    descriptivas.loc['rango'] = descriptivas.loc['max'] - descriptivas.loc['min']\n",
    "    descriptivas.loc['IQR'] = descriptivas.loc['75%'] - descriptivas.loc['25%']\n",
    "    descriptivas.loc['coef de var'] = descriptivas.loc['std']/descriptivas.loc['mean']\n",
    "    descriptivas.loc['skewness'] = du.data.skew(numeric_only=True)\n",
    "    descriptivas.loc['kurtosis'] = du.data.kurtosis(numeric_only=True)\n",
    "    return descriptivas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LM4dC7lBHJoT"
   },
   "source": [
    "# Cargar Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R2C-zrtBHJoT"
   },
   "outputs": [],
   "source": [
    "du = DataUtils(\n",
    "    Path(r'..\\data').resolve().absolute(),\n",
    "    \"kc_house_dataDS.parquet\",\n",
    "    lambda path: pd.read_parquet(path),\n",
    "    lambda df, path: df.to_parquet(path)\n",
    ")\n",
    "du.data = du.load_data(du.interim_path.joinpath(du.input_file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descripcion General del Dataset\n",
    "- numero de filas y columnas\n",
    "- tipos de datos y si estan correctos\n",
    "\n",
    "Durante la exploración inicial se realizó la conversión de los tipos de datos, y la correcta representación de datos nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = du.data.shape\n",
    "filas = shape[0]\n",
    "columnas = shape[1]\n",
    "print(f'El conjunto de datos se compone de {filas} filas y {columnas} columnas.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "du.data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas las columnas son del tipo correcto a excepción de date, se deberá hacer la conversión de este campo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza de calidad de datos general\n",
    "- Filas con valores exactamente iguales (duplicados)\n",
    "- Columnas duplicadas\n",
    "- Columnas con valores constantes o sin informacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validar_duplicados(du.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "du.data = eliminar_duplicados(du.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validar indices duplicados\n",
    "son_duplicados = validar_index_duplicados(du.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisando los primeros registros duplicados\n",
    "du.data[son_duplicados].sort_values(by='index').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisando los registros duplicados por index, se encuentra que muchas columnas tienen los mismos valores , lo único que cambia es que hay algunos faltantes y hay otros valores extremadamente bajos o altos, adicionalmente se observan algunos registros de la columna date que no son fechas. Primero se convertirá los valores de la columna date a date y los que no puedan ser convertidos se reemplazarán por valores nulos, luego se reemplazarán los valores extremos por valores nulos, luego se calculará la mediana por index para las columnas numéricas y se reemplazarán los valores nulos por estas medianas. Luego se eliminarán filas duplicadas y se reevaluarán los index duplicados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convirtiendo la columna date a datetime\n",
    "du.data['date'] = pd.to_datetime(du.data['date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazando valores extremos, menores a -1e+10 o mayores a 1e+10\n",
    "columnas_numericas = [columna for columna in du.data.columns if columna != 'date']\n",
    "du.data[columnas_numericas] = du.data[columnas_numericas].where(lambda x: x > -1e+10, other=np.nan).where(lambda x: x < 1e+10, other=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se reemplazan los valores extremos por la media\n",
    "# Nota: No se considera que haya data leakage pues los valores reemplazados son entre registros con el mismo index y como \n",
    "# al final se va a dejar un dataset con index únicos, no hay riesgo que estén tanto en el set de entrenamiento como en el de\n",
    "# test\n",
    "for columna_numerica in columnas_numericas:\n",
    "    du.data[columna_numerica]=du.data[columna_numerica].fillna(du.data.groupby('index')[columna_numerica].transform('median'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazando fechas nulas por la primera fecha no nula\n",
    "du.data['date'] = du.data['date'].fillna(du.data.groupby(['index'], sort=False)['date'].apply(lambda x: x.ffill().bfill()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para las siguientes columnas, un cero representa un dato nulo, por lo tanto se reemplazarán.\n",
    "- sqft_basement\n",
    "- yr_renovated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazando ceros por valores nulos\n",
    "du.data[['sqft_basement', 'yr_renovated']] = du.data[['sqft_basement', 'yr_renovated']].replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validar_duplicados(du.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "du.data = eliminar_duplicados(du.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "son_duplicados = validar_index_duplicados(du.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validando columnas con valores constantes\n",
    "unicos=du.data.nunique()\n",
    "unicos[unicos==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La columna wertyj tiene valores constantes, por lo tanto se eliminará."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "du.data.drop(columns=list(unicos[unicos==1].index), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulos = du.data.isnull().sum()\n",
    "cant_unicos = du.data.apply(lambda x: len(x.unique()))\n",
    "porce = nulos/filas\n",
    "nulos = pd.DataFrame({'nulos':nulos, 'porc':porce, 'cant_unicos': cant_unicos})\n",
    "# Se contarán las filas que contengan algún dato nulo\n",
    "al_menos_un_nulo=du.data.isnull().any(axis=1).sum()\n",
    "nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'De {filas} registros, hay {al_menos_un_nulo} registros con al menos un valor nulo, representando el {al_menos_un_nulo/filas:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{du.data.shape=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividir el dataset en Training set y Test set\n",
    "\n",
    "Este paso debe ser al inicio de los proyectos,  Se deben realizar todas las transformaciones, preparación de datos y limpieza de los datos, en el train set y en la evaluacion se deben aplicarl al test set y a los datos nuevos que lleguen al sistema. Esta division inicial se hace para evitar data leakage de los datos de test a los datos de train, por ejemplo en las imputaciones.\n",
    "\n",
    "Por este motivo se realizara en esta parte.\n",
    "\n",
    "Division de los datos de entrenamiento (Train set) y de Evaluacion (test - set), las divisiones utilizadas son\n",
    "\n",
    "- 80% (train) , 20%(test)\n",
    "- 70% (train) , 30%(test)\n",
    "\n",
    "El **Train set** se hace para seleccion de Modelos y el **Test-set** solamente para la evaluacion Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test, validation = train_test_split(du.data, test_size=0.2, random_state=1)\n",
    "du.save_data(train_test, du.raw_train_test_path)\n",
    "du.save_data(validation, du.raw_validation_path)\n",
    "print(f'{train_test.shape=}')\n",
    "print(f'{validation.shape=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5gnmm4vdHJoV"
   },
   "source": [
    "# Descripcion  y Limpieza de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZYzna68bHJoW"
   },
   "outputs": [],
   "source": [
    "du.data = du.load_data(du.raw_train_test_path)\n",
    "print('Tipos de variables')\n",
    "du.data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AFSKQY4Amzwv"
   },
   "source": [
    "## Identificacion de Variables\n",
    "- Variables de entrada y de salida\n",
    "- Tipo de Variables (categoricas o Numericas)\n",
    "- Tipo de datos (int, float, string, factor, boolean, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bnXkopIFHJob"
   },
   "outputs": [],
   "source": [
    "columnas_no_entrada = {'date', 'index'}\n",
    "entradas = [column for column in du.data.columns if column not in columnas_no_entrada]\n",
    "print('Columnas de entrada:')\n",
    "print(', '.join(entradas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salida = 'date'\n",
    "print(f'Columna de salida: {salida}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisis General Univariable y Bivariable \n",
    "Analisis de cada una de las variables para lograr calidad de datos en cada columna\n",
    "- **Correccion del tipo de dato (numericas, categoricas, string) de cada columna (optimizar memoria)**\n",
    "- Deteccion de numero de datos faltantes\n",
    "- Deteccion de duplicados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k5CEar_Cnw2x"
   },
   "source": [
    "## Eliminar columnas de datos Innecesarios\n",
    "\n",
    "Se realizará un perfilado de los datos para identificar problemas de calidad no identificados anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bxoNbnANoJt8"
   },
   "outputs": [],
   "source": [
    "columnas_entrenamiento = entradas + [salida]\n",
    "profiler = ProfileReport(du.data[columnas_entrenamiento], explorative=True)\n",
    "\n",
    "profiler_to_file(profiler, '1_0.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficar = Plot()\n",
    "graficar.box(du.data, y='price').show()\n",
    "graficar.box(du.data, y='sqft_lot').show()\n",
    "graficar.box(du.data, y='bedrooms').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Columna       | Tipo               | Problemas   de calidad encontrados                   | Correcciones                                                                                                                                                                                                                                                                                                                                                                        |\n",
    "|---------------|--------------------|------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| df_index      |                    |                                                      |                                                                                                                                                                                                                                                                                                                                                                                     |\n",
    "| zipcode       | Categórica         |                                                      | Se eliminará                                                                                                                                                                                                                                                                                                                                                                        |\n",
    "| grade         | Categórica         |                                                      |                                                                                                                                                                                                                                                                                                                                                                                     |\n",
    "| sqft_basement | Numérica           | Muchos datos nulos                                   | Se encontró el 60.8%   nulos, se transformará esta columna en una columna categórica binaria que   diga si tiene sótano o no (Si el valor es nulo no tiene, de lo contrario si   tiene).                                                                                                                                                                                            |\n",
    "| view          | Categórica         |                                                      |                                                                                                                                                                                                                                                                                                                                                                                     |\n",
    "| bathrooms     | Numérica           |                                                      |                                                                                                                                                                                                                                                                                                                                                                                     |\n",
    "| bedrooms      | Numérica           |    Datos atípicos                                  | Se eliminarán registros que superen las 5 alcobas y no tengan ninguna                                                                                                                                                                                                                                                                                                                                                                                    |\n",
    "| sqft_above    | Numérica           | Tiene una distribución asimétrica                    | Se transformará para   normalizar la distribución.                                                                                                                                                                                                                                                                                                                                  |\n",
    "| sqft_living15 | Numérica           | Tiene una distribución asimétrica                    | Se transformará para   normalizar la distribución.                                                                                                                                                                                                                                                                                                                                  |\n",
    "| lat           |                    |                                                      | Se eliminará, esta   columna solo representa una posición, y como todas las casas están en la   misma ciudad, es la misma latitud.                                                                                                                                                                                                                                                  |\n",
    "| waterfront    | Categórica         |                                                      |                                                                                                                                                                                                                                                                                                                                                                                     |\n",
    "| floors        | Numérica           |                                                      |                                                                                                                                                                                                                                                                                                                                                                                     |\n",
    "| date          | fecha              |                                                      | Se utilizará esta   columna para calcular la cantidad de años transcurridos desde la construcción   de la propiedad hasta la venta de la misma.                                                                                                                                                                                                                                     |\n",
    "| yr_renovated  | Numérica           |                                                      | Se eliminará, será   reemplazada por una columna que indique si fue renovada o no sin importar el   año.                                                                                                                                                                                                                                                                            |\n",
    "| yr_built      |                    |                                                      | Se utilizará para   calcular los años transcurridos desde la construcción hasta la venta de la   propiedad, luego será eliminada.                                                                                                                                                                                                                                                   |\n",
    "| long          |                    |                                                      | Se eliminará, esta   columna solo representa una posición, y como todas las casas están en la   misma ciudad, es la misma longitud.                                                                                                                                                                                                                                                 |\n",
    "| jhygtf        |                    |                                                      | Es la misma columna   que yr_renovated, será eliminada.                                                                                                                                                                                                                                                                                                                             |\n",
    "| sqft_lot      | Numérica           | Se encontraron datos atípicos.                       | Se encontraron valores atípicos, se eliminarán registros mayores a 350K pies cuadrados |\n",
    "| price         | Numérica           | Tiene una distribución asimétrica   y datos atípicos | Se transformará para   normalizar la distribución. Se encontrarón precios de billones de dólares,   estos precios se consideran excesivos y por lo tanto se eliminarán aquellos   registros mayores a 1.13 millones (1.5* rango_intercuartil + Q3).                                                                                                                                                                      |\n",
    "| condition     | Categórica nominal |                                                      | Se aplicará one hot   encoding                                                                                                                                                                                                                                                                                                                                                      |\n",
    "| sqft_lot15    | Numérica           | Tiene una distribución asimétrica                    | Se transformará para   normalizar la distribución.                                                                                                                                                                                                                                                                                                                                  |\n",
    "| sqft_living   | Numérica           | Tiene una   distribución asimétrica                  | Se transformará para   normalizar la distribución.                                                                                                                                                                                                                                                                                                                                  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminación de outliers\n",
    "Se eliminarán aquellas residencias que superen el billón de dólares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{du.data.shape=}')\n",
    "du.data = du.data[du.data['price'] <= 1130000]\n",
    "du.data = du.data[du.data['sqft_lot'] <= 350000]\n",
    "du.data = du.data[du.data['bedrooms'] <= 5]\n",
    "du.data = du.data[du.data['bedrooms'] > 0]\n",
    "du.data = du.data[du.data['bathrooms'] <= 4]\n",
    "du.data = du.data[du.data['bathrooms'] >= 1]\n",
    "print(f'{du.data.shape=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversión tipos de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_categoricas = ['grade', 'view', 'waterfront', 'condition', 'zipcode']\n",
    "du.data[variables_categoricas] = du.data[variables_categoricas].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculo de variables adicionales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Años transcurridos entre la construcción de la vivienda y la venta de la misma columnas yr_built y date\n",
    "# Primero se extraerá el año de la fecha para realizar la resta con yr_built\n",
    "du.data['yr_date'] = du.data['date'].dt.year\n",
    "du.data['antiguedad_venta'] = du.data['yr_date'] - du.data['yr_built']\n",
    "du.data.drop(columns=['yr_date', 'date', 'yr_built'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminación de columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# du.data.drop(columns=['zipcode', 'lat', 'yr_renovated', 'long', 'jhygtf'], inplace=True)\n",
    "du.data.drop(columns=['lat', 'yr_renovated', 'long', 'jhygtf'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_numericas   = ['sqft_basement', 'bathrooms', 'bedrooms', 'sqft_above', 'sqft_living15', 'floors', 'sqft_lot', 'price', 'sqft_lot15',\n",
    "                         'sqft_living', 'antiguedad_venta']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2LmnrQtbHJox"
   },
   "source": [
    "## Procesamiento de Datos Faltantes\n",
    "Las opciones que se pueden usar dependiendo del analisis de los datos son:\n",
    "### Borrar Filas\n",
    "- Borrar las filas que les falten todos los datos\n",
    "- Borrar Solo las filas que les falta las variables mas importantes o la salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zFwqgwOhHJox"
   },
   "outputs": [],
   "source": [
    "columnas_datosFaltantes = [columna for columna in du.data.columns if columna != 'date' and columna !=   'sqft_basement' and columna != 'yr_renovated' ]\n",
    "du.data=du.data.dropna(subset=columnas_datosFaltantes)\n",
    "du.data.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GnkcN0goHJod"
   },
   "source": [
    "## Analisis Univariable\n",
    "\n",
    "Estadistico Descriptico y Analisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LEvH4-LGHJod"
   },
   "source": [
    "### Variables Numericas\n",
    "\n",
    "| Tendencia Central |   Medida de Dispersión    | Visualizacion |\n",
    "|:-----------------:|:-------------------------:|:-------------:|\n",
    "|       Media       |           Rango           |  Histogramas  |\n",
    "|      Mediana      |         Cuartiles         |   Boxplots    |\n",
    "|       Moda        | Rango inter cuartil (IQR) |               |\n",
    "|      Minimo       |         Varianza          |               |\n",
    "|      Maximo       |   Desviacion Estandard    |               |\n",
    "|         .         |         Skewness          |               |\n",
    "|         .         |         Kurtosis          |               |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CDTBsGi0HJoe"
   },
   "outputs": [],
   "source": [
    "calcular_descriptivas(du.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable_numerica in ['price'] + variables_numericas:\n",
    "    graficar.box(du.data, y=variable_numerica).show()\n",
    "\n",
    "for variable_numerica in ['price'] + variables_numericas:\n",
    "    graficar.histogram(du.data, x=variable_numerica, nbins=5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mXQHmtMbHJoh"
   },
   "source": [
    "### Variables Categoricas\n",
    "- Numero de elementos por categoria\n",
    "- Porcentaje de elementos por categoria\n",
    "- Graficos de barras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hPY0sHqNHJoi"
   },
   "outputs": [],
   "source": [
    "resumen = []\n",
    "\n",
    "for variable_categorica in variables_categoricas:\n",
    "    col = du.data[variable_categorica]\n",
    "    elms_cat = col.groupby(by=col).agg('count')\n",
    "    total = elms_cat.sum()\n",
    "    porc = elms_cat / total\n",
    "    porc.name = 'porc'\n",
    "    df = pd.DataFrame([elms_cat, porc]).transpose()\n",
    "    resumen.append(df)\n",
    "\n",
    "for tabla in resumen:\n",
    "    display(HTML(tabla.to_html()))\n",
    "    variable = tabla.columns[0]\n",
    "    fig = px.bar(tabla[variable], orientation='h', title=str(variable))\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jmf_f9TOHJok"
   },
   "source": [
    "## Analisis Bivariable\n",
    "Estadistico Descriptico y Analisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3aVUkwJVHJom"
   },
   "source": [
    "### Numericas vs Numericas\n",
    "- Scatter Plot\n",
    "- Heatmap\n",
    "- Correlacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "067r3JdGHJon"
   },
   "outputs": [],
   "source": [
    "corr_matrix = du.data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix['price'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las variables relacionadas con el tamaño del apartamento tienen mayor correlación con el precio del apartamento, se observa que la antiguedad de venta, no tiene correlación con el precio, por lo tanto esta columna será eliminada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "du.data.drop(columns='antiguedad_venta', inplace=True)\n",
    "# plot it\n",
    "sns.heatmap(corr_matrix, cmap='PuOr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T544jyPsHJos"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "plt.scatter(du.data['price'], du.data['bedrooms'])\n",
    "\n",
    "plt.xlabel('precio')\n",
    "plt.ylabel('cantidad de baños')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para reducir la cardinalidad del código zip, se dejarán los primeros dos digitos de este para no perder la información de ubicación y tener pocas columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "du.data['zipcode_short'] = (du.data['zipcode'].astype('int')//100).astype('category')\n",
    "graficar.scatter(du.data,x='price',y='sqft_living', color='zipcode_short')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se evidencia que las residencias con zipcode 981## tienen un tamaño de lote mas homogéneo que aquellas con zipcode 980##."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s4Fn2YIvHJpL"
   },
   "source": [
    "## Feature Engineering \n",
    "### Transformacion de Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario donde se almacenaran los transformadores\n",
    "transformers = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numericas a binarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se considerará que un apartamento tiene sótano si sqft_basement está nulo.\n",
    "\n",
    "du.data['tiene_sotano'] = du.data['sqft_basement'].notna()\n",
    "# Reemplazando true por 1 y false por 0\n",
    "du.data['tiene_sotano'] = du.data['tiene_sotano'].astype('int').astype('category')\n",
    "du.data.drop(columns='sqft_basement', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jYPdefrhHJpS"
   },
   "source": [
    "#### Logaritmica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wU-lW1AQHJpS"
   },
   "outputs": [],
   "source": [
    "# Se transformarán las siguientes variables: sqft_above, sqft_living15, sqft_lot, price, sqft_lot15, sqft_living\n",
    "columnas = ['sqft_above', 'sqft_living15', 'sqft_lot', 'sqft_lot15', 'sqft_living']\n",
    "pt = PowerTransformer(method='box-cox')\n",
    "pty = PowerTransformer(method='box-cox')\n",
    "pt.fit(du.data[columnas])\n",
    "pty.fit(du.data[['price']])\n",
    "transformers['PowerTransformer'] = pt\n",
    "transformers['PowerTransformer_y'] = pty\n",
    "du.data[columnas] = pt.transform(du.data[columnas])\n",
    "du.data[['price']] = pty.transform(du.data[['price']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "profiler2 = ProfileReport(du.data[columnas], explorative=True)\n",
    "profiler_to_file(profiler2, 'power_transform.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se revisará nuevamente la distribución de las variables con box plots e histogramas\n",
    "for variable_numerica in ['price'] + columnas:\n",
    "    graficar.box(du.data, y=variable_numerica).show()\n",
    "\n",
    "for variable_numerica in ['price'] + columnas:\n",
    "    graficar.histogram(du.data, x=variable_numerica, nbins=20).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calcular_descriptivas(du.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de realizar la transformación de las variables, se encuentra que sqft_lot y sqft_lot15 siguen teniendo una alta kurtosis, por lo tanto se procederá a convertirlas en variables categóricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_a_categoricas = ['sqft_lot', 'sqft_lot15']\n",
    "kbd = KBinsDiscretizer(strategy='kmeans', encode='ordinal')\n",
    "kbd.fit(du.data[columnas_a_categoricas])\n",
    "transformers['KBinsDiscretizer'] = kbd\n",
    "du.data[columnas_a_categoricas] = kbd.transform(du.data[columnas_a_categoricas])\n",
    "du.data[columnas_a_categoricas] = du.data[columnas_a_categoricas].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I6PpnSEDHJpY"
   },
   "source": [
    "## Analisis Univariable y Bivariable Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiler3 = ProfileReport(du.data, explorative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiler_to_file(profiler3, '2_0_transformacion_final.html')\n",
    "profiler3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= du.data[['grade','view','condition']]\n",
    "sns.distplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "du.data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uRwep7LjHJpZ"
   },
   "source": [
    "### Variables de entrada\n",
    "- grade  \n",
    "- view  \n",
    "- bathrooms  \n",
    "- bedrooms  \n",
    "- sqft_above  \n",
    "- sqft_living15  \n",
    "- waterfront  \n",
    "- floors  \n",
    "- sqft_lot  \n",
    "- condition  \n",
    "- sqft_lot15  \n",
    "- sqft_living  \n",
    "- tiene_sotano  \n",
    "\n",
    "### Variables de salida\n",
    "- price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELAMIENTO DE LOS DATOS (MACHINE LEARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_entrada = ['grade', 'view', 'bathrooms', 'bedrooms', 'sqft_above', 'sqft_living15', 'waterfront', 'floors', 'sqft_lot', 'condition', 'sqft_lot15', 'sqft_living', 'tiene_sotano']\n",
    "variable_salida  = 'price'\n",
    "du.data = du.data[variables_entrada + [variable_salida]]\n",
    "# Variables categóricas con las que se realizará onehotencoding\n",
    "columnas_one_hot = ['grade', 'view', 'waterfront', 'sqft_lot', 'condition', 'sqft_lot15', 'tiene_sotano']\n",
    "ohe = OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.fit(du.data[columnas_one_hot])\n",
    "transformers['OneHotEncoder'] = ohe\n",
    "temp = pd.DataFrame(ohe.transform(du.data[columnas_one_hot]), columns=ohe.get_feature_names_out(), index=du.data.index).copy()\n",
    "du.data.drop(columns=columnas_one_hot, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "du.data = pd.concat([du.data, temp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_name = 'price'\n",
    "x_names = [columna for columna in du.data.columns if not columna == 'price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validacion y Evaluacion Cruzada (k-fold Cross Validation)\n",
    "\n",
    "Se hace seleccion de los mejores modelos usando el Training Set y k-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos_a_probar = [('SGD',SGDRegressor()), ('SVR',SVR())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "for modelo in modelos_a_probar:\n",
    "    scores[modelo[0]] = {}\n",
    "    scores[modelo[0]]['scores'] = cross_val_score(modelo[1], du.data[x_names], du.data[y_name], cv=5, scoring='r2')\n",
    "    scores[modelo[0]]['media'] = np.mean(scores[modelo[0]]['scores'])\n",
    "    scores[modelo[0]]['std'] = np.std(scores[modelo[0]]['scores'])\n",
    "    scores[modelo[0]]['coef. var.'] = scores[modelo[0]]['std'] / scores[modelo[0]]['media']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos_a_probar[0][1].fit(du.data[x_names], du.data[y_name])\n",
    "modelos_a_probar[1][1].fit(du.data[x_names], du.data[y_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = {}\n",
    "y_predict['SGD'] = modelos_a_probar[0][1].predict(du.data[x_names])\n",
    "y_predict['SVR'] = modelos_a_probar[1][1].predict(du.data[x_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficar.scatter(pd.DataFrame({'y_real': du.data[y_name], 'y_pred': y_predict['SVR']}), x='y_real', y='y_pred').show()\n",
    "graficar.scatter(pd.DataFrame({'y_real': du.data[y_name], 'y_pred': y_predict['SGD']}), x='y_real', y='y_pred').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se escogerá el modelo SVR un mejor desempeño"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizacion de Hiper parametros (Hyper Parameter optimization)\n",
    "\n",
    "Se seleccionan solo los mejores modelos para realizar el ajuste de hiperparametros, ya que tiene una carga computacional alta.\n",
    "\n",
    "Al final se obtienen los parametros del mejor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluacion final del modelo con el Test set\n",
    "\n",
    "Tomar los parametros obtenidos en el paso anterior, se crea el modelo con esos pararmetros y se entrena el modelo con todos los datos del **Train -set**\n",
    "\n",
    "Finalmente se realiza la evaluacion (segun su problema si es de regresion o de clasificacion) usando el **Test - set** para definir si el modelo obtenido esta bien. Compare los resultados con el **Train -set** vs los resultados con el **Test - set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementacion del Modelo (Deploying)\n",
    "Con el análisis básico y el ajuste hecho, comienza el trabajo real (ingeniería).\n",
    "\n",
    "El último paso para poner en produccion el modelo de prediccion sera:\n",
    "1. Entrenarlo en todo el conjunto de datos nuevamente, para hacer un uso completo de todos los datos disponibles. \n",
    "2. Usar los mejores parámetros encontrados mediante la validación cruzada, por supuesto. Esto es muy similar a lo que hicimos al principio, pero esta vez teniendo una idea de su comportamiento y estabilidad. La evaluación se realizó con honestidad, en divisiones distintas de entrenamiento / prueba.\n",
    "\n",
    "El predictor final se puede serializar y grabar en el disco, de modo que la próxima vez que lo usemos, podemos omitir todo el entrenamiento y usar el modelo capacitado directamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle # Esta es una libreria de serializacion nativa de python, puede tener problemas de seguridad\n",
    "from joblib import dump # libreria de serializacion\n",
    "\n",
    "# garbar el modelo en un archivo\n",
    "#dump(Modelo_final, 'Nombre_Archivo_Modelo.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comunicacion de Resultados (Data Story Telling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ayudas Y Referencias\n",
    "\n",
    "- https://medium.com/@joserzapata/paso-a-paso-en-un-proyecto-machine-learning-bcdd0939d387\n",
    "- [Proyecto de Principio a Final sobre readmision de pacientes con Diabetes](https://github.com/JoseRZapata/Readmission-ML-Project)\n",
    "\n",
    "- [a-complete-machine-learning-walk-through-in-python-part-one](https://towardsdatascience.com/a-complete-machine-learning-walk-through-in-python-part-one-c62152f39420)\n",
    "\n",
    "\n",
    "- [a-starter-pack-to-exploratory-data-analysis-with-python-pandas-seaborn-and-scikit-learn](https://towardsdatascience.com/a-starter-pack-to-exploratory-data-analysis-with-python-pandas-seaborn-and-scikit-learn-a77889485baf#249d)\n",
    "\n",
    "- [a-data-science-for-good-machine-learning-project-walk-through-in-python-part-one](https://towardsdatascience.com/a-data-science-for-good-machine-learning-project-walk-through-in-python-part-one-1977dd701dbc)\n",
    "\n",
    "- [Ejemplos de Kaggle](https://www.kaggle.com/kernels?sortBy=hotness&group=everyone&pageSize=20&language=Python&kernelType=Notebook)\n",
    "\n",
    "- [END to END ML from data colletion to deployment](https://medium.com/datadriveninvestor/end-to-end-machine-learning-from-data-collection-to-deployment-ce74f51ca203)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docente: [Jose R. Zapata](https://joserzapata.github.io)\n",
    "- https://joserzapata.github.io\n",
    "- https://twitter.com/joserzapata\n",
    "- https://www.linkedin.com/in/jose-ricardo-zapata-gonzalez/   "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "mXQHmtMbHJoh",
    "3aVUkwJVHJom",
    "9SfZHh6oHJor",
    "1S_iRK8rHJo0",
    "Ey5Lk8evHJo3",
    "0Y0UV-GVHJo6",
    "he4lxsEUHJpM",
    "h0FKIrJHHJpO",
    "jYPdefrhHJpS",
    "zUundEM6HJpT",
    "2GNrgJzHHJpW",
    "uRwep7LjHJpZ",
    "JCcM4XFbHJpd"
   ],
   "name": "Trabajo_Preparacion_Datos_JoseR_Zapata.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "nbTranslate": {
   "displayLangs": [
    "es",
    "en"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "es",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Contenido",
   "title_sidebar": "Contenido",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "447c0f0993c7e50bc10ddc9bd7e362220c6ef046a7e5a6eb2fbe70cad79928d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
